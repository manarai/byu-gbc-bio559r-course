{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Foundations: Linear Algebra and Network Theory in Systems Biology\n",
    "\n",
    "**BIO559R - Introduction to Systems Biology**  \n",
    "**Module 2: Mathematical Foundations**\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Apply linear algebra** to analyze metabolic networks and pathways\n",
    "2. **Perform flux balance analysis** using stoichiometric matrices\n",
    "3. **Use Principal Component Analysis** for dimensionality reduction in omics data\n",
    "4. **Analyze network topology** using graph theory metrics\n",
    "5. **Identify network motifs** and their biological significance\n",
    "6. **Visualize complex networks** using Python and R\n",
    "7. **Interpret biological meaning** from mathematical network analysis\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic linear algebra (matrices, vectors, eigenvalues)\n",
    "- Python programming fundamentals\n",
    "- Understanding of biological networks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "\n",
    "# Load R magic for visualization\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Linear Algebra Fundamentals for Biology\n",
    "\n",
    "### Matrix Operations in Biological Context\n",
    "\n",
    "In systems biology, matrices represent:\n",
    "- **Stoichiometric matrices**: Metabolic network structure\n",
    "- **Adjacency matrices**: Network connectivity\n",
    "- **Expression matrices**: Gene expression data\n",
    "- **Interaction matrices**: Protein-protein interactions\n",
    "\n",
    "Key operations:\n",
    "- **Matrix multiplication**: Pathway flux calculations\n",
    "- **Null space**: Steady-state flux distributions\n",
    "- **Eigendecomposition**: Principal components, network centrality\n",
    "- **Matrix inversion**: Solving linear systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Basic Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example biological matrices\n",
    "\n",
    "# Stoichiometric matrix for a simple pathway: A -> B -> C\n",
    "# Reactions: R1: A -> B, R2: B -> C, R3: A -> (external)\n",
    "S = np.array([\n",
    "    [-1,  0,  -1],  # Metabolite A\n",
    "    [ 1, -1,   0],  # Metabolite B  \n",
    "    [ 0,  1,   0]   # Metabolite C\n",
    "])\n",
    "\n",
    "print(\"Stoichiometric Matrix S:\")\n",
    "print(S)\n",
    "print(f\"Shape: {S.shape} (metabolites x reactions)\")\n",
    "\n",
    "# Example flux vector\n",
    "v = np.array([2.0, 1.5, 0.5])  # Flux through each reaction\n",
    "print(f\"\\nFlux vector v: {v}\")\n",
    "\n",
    "# Calculate metabolite production rates\n",
    "production_rates = S @ v\n",
    "print(f\"\\nMetabolite production rates (S·v): {production_rates}\")\n",
    "\n",
    "# Check if this is a steady state (all rates should be zero)\n",
    "is_steady_state = np.allclose(production_rates, 0, atol=1e-10)\n",
    "print(f\"Is steady state? {is_steady_state}\")\n",
    "\n",
    "# Find a steady-state flux distribution\n",
    "# For steady state: S·v = 0\n",
    "# We need to find the null space of S\n",
    "U, s, Vt = linalg.svd(S)\n",
    "null_space = Vt[len(s):, :].T\n",
    "print(f\"\\nNull space of S (steady-state flux modes):\")\n",
    "print(null_space)\n",
    "\n",
    "# Verify steady state\n",
    "if null_space.size > 0:\n",
    "    steady_flux = null_space[:, 0] * 2  # Scale the first mode\n",
    "    steady_rates = S @ steady_flux\n",
    "    print(f\"\\nSteady-state flux: {steady_flux}\")\n",
    "    print(f\"Production rates: {steady_rates}\")\n",
    "    print(f\"Is steady state? {np.allclose(steady_rates, 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Metabolic Flux Balance Analysis\n",
    "\n",
    "### Theory\n",
    "\n",
    "Flux Balance Analysis (FBA) uses linear programming to find optimal flux distributions in metabolic networks:\n",
    "\n",
    "**Maximize**: $c^T v$ (objective function)\n",
    "\n",
    "**Subject to**:\n",
    "- $S \\cdot v = 0$ (steady-state constraint)\n",
    "- $v_{min} \\leq v \\leq v_{max}$ (flux bounds)\n",
    "\n",
    "Where:\n",
    "- $S$ is the stoichiometric matrix\n",
    "- $v$ is the flux vector\n",
    "- $c$ is the objective coefficient vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Simple Metabolic Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more complex metabolic network\n",
    "# Network: Glucose -> G6P -> F6P -> Pyruvate\n",
    "#                     |-> Biomass\n",
    "\n",
    "# Reactions:\n",
    "# R1: Glucose -> G6P\n",
    "# R2: G6P -> F6P  \n",
    "# R3: F6P -> Pyruvate\n",
    "# R4: G6P -> Biomass\n",
    "# R5: Glucose uptake (external)\n",
    "\n",
    "metabolites = ['Glucose', 'G6P', 'F6P', 'Pyruvate', 'Biomass']\n",
    "reactions = ['R1_Glc_to_G6P', 'R2_G6P_to_F6P', 'R3_F6P_to_Pyr', 'R4_G6P_to_Bio', 'R5_Glc_uptake']\n",
    "\n",
    "# Stoichiometric matrix\n",
    "S_metabolic = np.array([\n",
    "    [-1,  0,  0,  0,  1],  # Glucose\n",
    "    [ 1, -1,  0, -1,  0],  # G6P\n",
    "    [ 0,  1, -1,  0,  0],  # F6P\n",
    "    [ 0,  0,  1,  0,  0],  # Pyruvate\n",
    "    [ 0,  0,  0,  1,  0]   # Biomass\n",
    "])\n",
    "\n",
    "print(\"Metabolic Network Stoichiometric Matrix:\")\n",
    "print(\"Metabolites:\", metabolites)\n",
    "print(\"Reactions:\", reactions)\n",
    "print(S_metabolic)\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "S_df = pd.DataFrame(S_metabolic, \n",
    "                   index=metabolites, \n",
    "                   columns=reactions)\n",
    "print(\"\\nStoichiometric Matrix as DataFrame:\")\n",
    "print(S_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the network structure\n",
    "def analyze_stoichiometric_matrix(S, metabolite_names, reaction_names):\n",
    "    \"\"\"\n",
    "    Analyze properties of a stoichiometric matrix\n",
    "    \"\"\"\n",
    "    print(f\"Matrix dimensions: {S.shape[0]} metabolites × {S.shape[1]} reactions\")\n",
    "    print(f\"Matrix rank: {linalg.matrix_rank(S)}\")\n",
    "    \n",
    "    # Find null space (steady-state flux modes)\n",
    "    U, s, Vt = linalg.svd(S)\n",
    "    null_space_dim = S.shape[1] - linalg.matrix_rank(S)\n",
    "    print(f\"Null space dimension: {null_space_dim}\")\n",
    "    \n",
    "    if null_space_dim > 0:\n",
    "        null_vectors = Vt[-null_space_dim:, :].T\n",
    "        print(\"\\nSteady-state flux modes:\")\n",
    "        for i in range(null_space_dim):\n",
    "            mode = null_vectors[:, i]\n",
    "            print(f\"Mode {i+1}:\")\n",
    "            for j, (reaction, flux) in enumerate(zip(reaction_names, mode)):\n",
    "                if abs(flux) > 1e-10:\n",
    "                    print(f\"  {reaction}: {flux:.3f}\")\n",
    "        \n",
    "        return null_vectors\n",
    "    else:\n",
    "        print(\"No steady-state flux modes found (overdetermined system)\")\n",
    "        return None\n",
    "\n",
    "flux_modes = analyze_stoichiometric_matrix(S_metabolic, metabolites, reactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Flux Balance Analysis Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "\n",
    "def flux_balance_analysis(S, c, bounds=None):\n",
    "    \"\"\"\n",
    "    Perform Flux Balance Analysis using linear programming\n",
    "    \n",
    "    Parameters:\n",
    "    S: stoichiometric matrix\n",
    "    c: objective coefficients (negative for maximization)\n",
    "    bounds: flux bounds for each reaction\n",
    "    \"\"\"\n",
    "    n_reactions = S.shape[1]\n",
    "    \n",
    "    # Default bounds: allow reversible reactions\n",
    "    if bounds is None:\n",
    "        bounds = [(-1000, 1000)] * n_reactions\n",
    "    \n",
    "    # Equality constraints: S·v = 0 (steady state)\n",
    "    A_eq = S\n",
    "    b_eq = np.zeros(S.shape[0])\n",
    "    \n",
    "    # Solve linear programming problem\n",
    "    result = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Define objective: maximize biomass production (R4)\n",
    "objective = np.zeros(len(reactions))\n",
    "objective[3] = -1  # Negative because linprog minimizes\n",
    "\n",
    "# Define flux bounds\n",
    "flux_bounds = [\n",
    "    (0, 1000),    # R1: irreversible\n",
    "    (0, 1000),    # R2: irreversible\n",
    "    (0, 1000),    # R3: irreversible\n",
    "    (0, 1000),    # R4: irreversible (biomass)\n",
    "    (0, 10)       # R5: glucose uptake limited\n",
    "]\n",
    "\n",
    "# Perform FBA\n",
    "fba_result = flux_balance_analysis(S_metabolic, objective, flux_bounds)\n",
    "\n",
    "print(\"FBA Results:\")\n",
    "print(f\"Optimization successful: {fba_result.success}\")\n",
    "print(f\"Optimal objective value: {-fba_result.fun:.3f}\")\n",
    "print(\"\\nOptimal flux distribution:\")\n",
    "for reaction, flux in zip(reactions, fba_result.x):\n",
    "    print(f\"{reaction}: {flux:.3f}\")\n",
    "\n",
    "# Verify steady state\n",
    "production_rates = S_metabolic @ fba_result.x\n",
    "print(\"\\nMetabolite production rates (should be ~0):\")\n",
    "for metabolite, rate in zip(metabolites, production_rates):\n",
    "    print(f\"{metabolite}: {rate:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization data for FBA results\n",
    "fba_df = pd.DataFrame({\n",
    "    'reaction': reactions,\n",
    "    'flux': fba_result.x,\n",
    "    'reaction_type': ['Central_Metabolism', 'Central_Metabolism', 'Central_Metabolism', 'Biomass', 'Uptake']\n",
    "})\n",
    "\n",
    "print(\"FBA results prepared for visualization:\")\n",
    "print(fba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i fba_df -w 12 -h 8\n",
    "\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "\n",
    "# Create FBA results visualization\n",
    "p1 <- ggplot(fba_df, aes(x = reorder(reaction, flux), y = flux, fill = reaction_type)) +\n",
    "    geom_col(alpha = 0.8) +\n",
    "    coord_flip() +\n",
    "    scale_fill_manual(values = c(\n",
    "        \"Central_Metabolism\" = \"#2ca02c\",\n",
    "        \"Biomass\" = \"#d62728\",\n",
    "        \"Uptake\" = \"#1f77b4\"\n",
    "    )) +\n",
    "    labs(\n",
    "        title = \"Flux Balance Analysis Results\",\n",
    "        subtitle = \"Optimal flux distribution for biomass maximization\",\n",
    "        x = \"Reaction\",\n",
    "        y = \"Flux (mmol/gDW/h)\",\n",
    "        fill = \"Reaction Type\"\n",
    "    ) +\n",
    "    theme_classic() +\n",
    "    theme(\n",
    "        plot.title = element_text(size = 16, hjust = 0.5),\n",
    "        plot.subtitle = element_text(size = 12, hjust = 0.5),\n",
    "        axis.title = element_text(size = 12),\n",
    "        axis.text = element_text(size = 10),\n",
    "        legend.title = element_text(size = 12),\n",
    "        legend.text = element_text(size = 10)\n",
    "    )\n",
    "\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Principal Component Analysis for Omics Data\n",
    "\n",
    "### Theory\n",
    "\n",
    "Principal Component Analysis (PCA) reduces dimensionality while preserving variance:\n",
    "\n",
    "1. **Standardize** the data matrix $X$\n",
    "2. **Compute** covariance matrix $C = \\frac{1}{n-1}X^TX$\n",
    "3. **Find** eigenvalues and eigenvectors of $C$\n",
    "4. **Project** data onto principal components\n",
    "\n",
    "Applications:\n",
    "- Gene expression analysis\n",
    "- Metabolomics data exploration\n",
    "- Quality control in omics experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: PCA on Simulated Gene Expression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simulated gene expression data\n",
    "def generate_expression_data(n_samples=100, n_genes=1000, n_conditions=3):\n",
    "    \"\"\"\n",
    "    Generate simulated gene expression data with different conditions\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Base expression levels\n",
    "    base_expression = np.random.lognormal(mean=2, sigma=1, size=n_genes)\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for condition in range(n_conditions):\n",
    "        n_samples_condition = n_samples // n_conditions\n",
    "        \n",
    "        for sample in range(n_samples_condition):\n",
    "            # Add condition-specific effects\n",
    "            condition_effect = np.random.normal(0, 0.5, n_genes)\n",
    "            if condition == 1:  # Condition 1: upregulate first 100 genes\n",
    "                condition_effect[:100] += 2\n",
    "            elif condition == 2:  # Condition 2: downregulate genes 100-200\n",
    "                condition_effect[100:200] -= 1.5\n",
    "            \n",
    "            # Add noise\n",
    "            noise = np.random.normal(0, 0.3, n_genes)\n",
    "            \n",
    "            expression = base_expression * np.exp(condition_effect + noise)\n",
    "            data.append(expression)\n",
    "            labels.append(f'Condition_{condition}')\n",
    "    \n",
    "    return np.array(data), labels\n",
    "\n",
    "# Generate data\n",
    "expression_data, condition_labels = generate_expression_data()\n",
    "print(f\"Generated expression data: {expression_data.shape}\")\n",
    "print(f\"Conditions: {set(condition_labels)}\")\n",
    "\n",
    "# Log-transform and standardize\n",
    "log_expression = np.log2(expression_data + 1)\n",
    "scaler = StandardScaler()\n",
    "scaled_expression = scaler.fit_transform(log_expression)\n",
    "\n",
    "print(f\"Data after log-transformation and scaling: {scaled_expression.shape}\")\n",
    "print(f\"Mean: {scaled_expression.mean():.3f}, Std: {scaled_expression.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca_result = pca.fit_transform(scaled_expression)\n",
    "\n",
    "print(\"PCA Results:\")\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Cumulative explained variance: {np.cumsum(pca.explained_variance_ratio_)}\")\n",
    "\n",
    "# Create PCA results DataFrame\n",
    "pca_df = pd.DataFrame({\n",
    "    'PC1': pca_result[:, 0],\n",
    "    'PC2': pca_result[:, 1],\n",
    "    'PC3': pca_result[:, 2],\n",
    "    'condition': condition_labels,\n",
    "    'sample_id': [f'Sample_{i}' for i in range(len(condition_labels))]\n",
    "})\n",
    "\n",
    "# Variance explained data\n",
    "variance_df = pd.DataFrame({\n",
    "    'PC': [f'PC{i+1}' for i in range(10)],\n",
    "    'variance_explained': pca.explained_variance_ratio_,\n",
    "    'cumulative_variance': np.cumsum(pca.explained_variance_ratio_)\n",
    "})\n",
    "\n",
    "print(\"\\nPCA data prepared for visualization\")\n",
    "print(f\"PCA DataFrame shape: {pca_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i pca_df -i variance_df -w 14 -h 10\n",
    "\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(gridExtra)\n",
    "\n",
    "# PCA scatter plot\n",
    "p2a <- ggplot(pca_df, aes(x = PC1, y = PC2, color = condition)) +\n",
    "    geom_point(size = 3, alpha = 0.7) +\n",
    "    stat_ellipse(level = 0.68, linetype = \"dashed\") +\n",
    "    scale_color_manual(values = c(\n",
    "        \"Condition_0\" = \"#1f77b4\",\n",
    "        \"Condition_1\" = \"#ff7f0e\",\n",
    "        \"Condition_2\" = \"#2ca02c\"\n",
    "    )) +\n",
    "    labs(\n",
    "        title = \"PCA of Gene Expression Data\",\n",
    "        x = paste0(\"PC1 (\", round(variance_df$variance_explained[1] * 100, 1), \"% variance)\"),\n",
    "        y = paste0(\"PC2 (\", round(variance_df$variance_explained[2] * 100, 1), \"% variance)\"),\n",
    "        color = \"Condition\"\n",
    "    ) +\n",
    "    theme_classic() +\n",
    "    theme(\n",
    "        plot.title = element_text(size = 14, hjust = 0.5),\n",
    "        axis.title = element_text(size = 12),\n",
    "        legend.title = element_text(size = 12)\n",
    "    )\n",
    "\n",
    "# Variance explained plot\n",
    "p2b <- ggplot(variance_df[1:5,], aes(x = PC, y = variance_explained)) +\n",
    "    geom_col(fill = \"steelblue\", alpha = 0.7) +\n",
    "    geom_text(aes(label = paste0(round(variance_explained * 100, 1), \"%\")), \n",
    "              vjust = -0.5, size = 3) +\n",
    "    labs(\n",
    "        title = \"Variance Explained by Principal Components\",\n",
    "        x = \"Principal Component\",\n",
    "        y = \"Proportion of Variance Explained\"\n",
    "    ) +\n",
    "    theme_classic() +\n",
    "    theme(\n",
    "        plot.title = element_text(size = 14, hjust = 0.5),\n",
    "        axis.title = element_text(size = 12)\n",
    "    )\n",
    "\n",
    "grid.arrange(p2a, p2b, nrow = 2, heights = c(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Gene Loading Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze gene loadings (contributions to PCs)\n",
    "def analyze_gene_loadings(pca_model, n_top_genes=20):\n",
    "    \"\"\"\n",
    "    Analyze which genes contribute most to each principal component\n",
    "    \"\"\"\n",
    "    loadings = pca_model.components_\n",
    "    \n",
    "    loading_results = []\n",
    "    \n",
    "    for pc in range(min(3, loadings.shape[0])):  # Analyze first 3 PCs\n",
    "        pc_loadings = loadings[pc, :]\n",
    "        \n",
    "        # Get top positive and negative loadings\n",
    "        top_positive_idx = np.argsort(pc_loadings)[-n_top_genes//2:]\n",
    "        top_negative_idx = np.argsort(pc_loadings)[:n_top_genes//2]\n",
    "        \n",
    "        for idx in top_positive_idx:\n",
    "            loading_results.append({\n",
    "                'PC': f'PC{pc+1}',\n",
    "                'gene': f'Gene_{idx}',\n",
    "                'loading': pc_loadings[idx],\n",
    "                'direction': 'Positive'\n",
    "            })\n",
    "        \n",
    "        for idx in top_negative_idx:\n",
    "            loading_results.append({\n",
    "                'PC': f'PC{pc+1}',\n",
    "                'gene': f'Gene_{idx}',\n",
    "                'loading': pc_loadings[idx],\n",
    "                'direction': 'Negative'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(loading_results)\n",
    "\n",
    "# Analyze loadings\n",
    "loadings_df = analyze_gene_loadings(pca)\n",
    "print(\"Gene loadings analysis:\")\n",
    "print(loadings_df.head(10))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nTop contributing genes by PC:\")\n",
    "for pc in ['PC1', 'PC2', 'PC3']:\n",
    "    pc_data = loadings_df[loadings_df['PC'] == pc]\n",
    "    top_gene = pc_data.loc[pc_data['loading'].abs().idxmax()]\n",
    "    print(f\"{pc}: {top_gene['gene']} (loading: {top_gene['loading']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i loadings_df -w 12 -h 8\n",
    "\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "\n",
    "# Create gene loadings plot\n",
    "p3 <- loadings_df %>%\n",
    "    filter(PC %in% c(\"PC1\", \"PC2\")) %>%\n",
    "    ggplot(aes(x = reorder(gene, abs(loading)), y = loading, fill = direction)) +\n",
    "    geom_col() +\n",
    "    facet_wrap(~PC, scales = \"free_y\") +\n",
    "    coord_flip() +\n",
    "    scale_fill_manual(values = c(\"Positive\" = \"#d62728\", \"Negative\" = \"#1f77b4\")) +\n",
    "    labs(\n",
    "        title = \"Gene Loadings on Principal Components\",\n",
    "        subtitle = \"Top contributing genes to PC1 and PC2\",\n",
    "        x = \"Gene\",\n",
    "        y = \"Loading Value\",\n",
    "        fill = \"Direction\"\n",
    "    ) +\n",
    "    theme_classic() +\n",
    "    theme(\n",
    "        plot.title = element_text(size = 16, hjust = 0.5),\n",
    "        plot.subtitle = element_text(size = 12, hjust = 0.5),\n",
    "        axis.title = element_text(size = 12),\n",
    "        axis.text.y = element_text(size = 8),\n",
    "        strip.text = element_text(size = 12)\n",
    "    )\n",
    "\n",
    "print(p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Network Theory and Graph Analysis\n",
    "\n",
    "### Theory\n",
    "\n",
    "Biological networks can be represented as graphs:\n",
    "- **Nodes**: Biological entities (genes, proteins, metabolites)\n",
    "- **Edges**: Interactions or relationships\n",
    "\n",
    "Key network metrics:\n",
    "- **Degree**: Number of connections per node\n",
    "- **Centrality**: Importance of nodes in the network\n",
    "- **Clustering**: Local connectivity patterns\n",
    "- **Path length**: Distance between nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Protein-Protein Interaction Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simulated protein-protein interaction network\n",
    "def create_ppi_network(n_proteins=50, connection_prob=0.1):\n",
    "    \"\"\"\n",
    "    Create a simulated protein-protein interaction network\n",
    "    \"\"\"\n",
    "    # Create random network\n",
    "    G = nx.erdos_renyi_graph(n_proteins, connection_prob)\n",
    "    \n",
    "    # Add protein names\n",
    "    protein_names = [f'Protein_{i:02d}' for i in range(n_proteins)]\n",
    "    mapping = {i: protein_names[i] for i in range(n_proteins)}\n",
    "    G = nx.relabel_nodes(G, mapping)\n",
    "    \n",
    "    # Add some hub proteins (highly connected)\n",
    "    hub_proteins = np.random.choice(protein_names, 5, replace=False)\n",
    "    for hub in hub_proteins:\n",
    "        # Connect hub to additional random proteins\n",
    "        targets = np.random.choice(protein_names, 8, replace=False)\n",
    "        for target in targets:\n",
    "            if hub != target:\n",
    "                G.add_edge(hub, target)\n",
    "    \n",
    "    return G, hub_proteins\n",
    "\n",
    "# Create PPI network\n",
    "ppi_network, hub_proteins = create_ppi_network()\n",
    "\n",
    "print(f\"PPI Network created:\")\n",
    "print(f\"Nodes: {ppi_network.number_of_nodes()}\")\n",
    "print(f\"Edges: {ppi_network.number_of_edges()}\")\n",
    "print(f\"Hub proteins: {hub_proteins}\")\n",
    "\n",
    "# Calculate network metrics\n",
    "def calculate_network_metrics(G):\n",
    "    \"\"\"\n",
    "    Calculate various network topology metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Basic metrics\n",
    "    metrics['degree'] = dict(G.degree())\n",
    "    metrics['clustering'] = nx.clustering(G)\n",
    "    \n",
    "    # Centrality measures\n",
    "    metrics['betweenness'] = nx.betweenness_centrality(G)\n",
    "    metrics['closeness'] = nx.closeness_centrality(G)\n",
    "    metrics['eigenvector'] = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "network_metrics = calculate_network_metrics(ppi_network)\n",
    "print(\"\\nNetwork metrics calculated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network analysis DataFrame\n",
    "network_df = pd.DataFrame({\n",
    "    'protein': list(ppi_network.nodes()),\n",
    "    'degree': [network_metrics['degree'][node] for node in ppi_network.nodes()],\n",
    "    'clustering': [network_metrics['clustering'][node] for node in ppi_network.nodes()],\n",
    "    'betweenness': [network_metrics['betweenness'][node] for node in ppi_network.nodes()],\n",
    "    'closeness': [network_metrics['closeness'][node] for node in ppi_network.nodes()],\n",
    "    'eigenvector': [network_metrics['eigenvector'][node] for node in ppi_network.nodes()],\n",
    "    'is_hub': [protein in hub_proteins for protein in ppi_network.nodes()]\n",
    "})\n",
    "\n",
    "print(\"Network analysis DataFrame:\")\n",
    "print(network_df.head())\n",
    "print(f\"\\nTop 5 proteins by degree:\")\n",
    "print(network_df.nlargest(5, 'degree')[['protein', 'degree', 'is_hub']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i network_df -w 14 -h 10\n",
    "\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(gridExtra)\n",
    "\n",
    "# Degree distribution\n",
    "p4a <- ggplot(network_df, aes(x = degree, fill = is_hub)) +\n",
    "    geom_histogram(bins = 15, alpha = 0.7) +\n",
    "    scale_fill_manual(values = c(\"FALSE\" = \"lightblue\", \"TRUE\" = \"red\")) +\n",
    "    labs(\n",
    "        title = \"Protein Degree Distribution\",\n",
    "        x = \"Degree (Number of Interactions)\",\n",
    "        y = \"Count\",\n",
    "        fill = \"Hub Protein\"\n",
    "    ) +\n",
    "    theme_classic()\n",
    "\n",
    "# Centrality comparison\n",
    "p4b <- ggplot(network_df, aes(x = degree, y = betweenness, color = is_hub, size = eigenvector)) +\n",
    "    geom_point(alpha = 0.7) +\n",
    "    scale_color_manual(values = c(\"FALSE\" = \"blue\", \"TRUE\" = \"red\")) +\n",
    "    scale_size_continuous(range = c(1, 4)) +\n",
    "    labs(\n",
    "        title = \"Network Centrality Analysis\",\n",
    "        x = \"Degree Centrality\",\n",
    "        y = \"Betweenness Centrality\",\n",
    "        color = \"Hub Protein\",\n",
    "        size = \"Eigenvector\\nCentrality\"\n",
    "    ) +\n",
    "    theme_classic()\n",
    "\n",
    "# Clustering coefficient vs degree\n",
    "p4c <- ggplot(network_df, aes(x = degree, y = clustering, color = is_hub)) +\n",
    "    geom_point(size = 2, alpha = 0.7) +\n",
    "    geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = \"dashed\") +\n",
    "    scale_color_manual(values = c(\"FALSE\" = \"blue\", \"TRUE\" = \"red\")) +\n",
    "    labs(\n",
    "        title = \"Clustering vs Degree\",\n",
    "        x = \"Degree\",\n",
    "        y = \"Clustering Coefficient\",\n",
    "        color = \"Hub Protein\"\n",
    "    ) +\n",
    "    theme_classic()\n",
    "\n",
    "grid.arrange(p4a, p4b, p4c, nrow = 2, ncol = 2, heights = c(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Network Motif Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directed gene regulatory network\n",
    "def create_gene_regulatory_network(n_genes=20):\n",
    "    \"\"\"\n",
    "    Create a simulated gene regulatory network with common motifs\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add genes\n",
    "    genes = [f'Gene_{i:02d}' for i in range(n_genes)]\n",
    "    G.add_nodes_from(genes)\n",
    "    \n",
    "    # Add some common network motifs\n",
    "    \n",
    "    # 1. Feed-forward loops\n",
    "    G.add_edges_from([\n",
    "        ('Gene_00', 'Gene_01'),  # X -> Y\n",
    "        ('Gene_00', 'Gene_02'),  # X -> Z\n",
    "        ('Gene_01', 'Gene_02'),  # Y -> Z\n",
    "    ])\n",
    "    \n",
    "    # 2. Feedback loops\n",
    "    G.add_edges_from([\n",
    "        ('Gene_03', 'Gene_04'),  # A -> B\n",
    "        ('Gene_04', 'Gene_03'),  # B -> A (mutual regulation)\n",
    "    ])\n",
    "    \n",
    "    # 3. Fan-out (one regulator, multiple targets)\n",
    "    master_regulator = 'Gene_05'\n",
    "    targets = ['Gene_06', 'Gene_07', 'Gene_08', 'Gene_09']\n",
    "    for target in targets:\n",
    "        G.add_edge(master_regulator, target)\n",
    "    \n",
    "    # 4. Fan-in (multiple regulators, one target)\n",
    "    regulators = ['Gene_10', 'Gene_11', 'Gene_12']\n",
    "    target = 'Gene_13'\n",
    "    for regulator in regulators:\n",
    "        G.add_edge(regulator, target)\n",
    "    \n",
    "    # Add some random edges\n",
    "    remaining_genes = genes[14:]\n",
    "    for i in range(len(remaining_genes) - 1):\n",
    "        if np.random.random() > 0.5:\n",
    "            G.add_edge(remaining_genes[i], remaining_genes[i+1])\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Create GRN\n",
    "grn = create_gene_regulatory_network()\n",
    "\n",
    "print(f\"Gene Regulatory Network:\")\n",
    "print(f\"Nodes: {grn.number_of_nodes()}\")\n",
    "print(f\"Edges: {grn.number_of_edges()}\")\n",
    "\n",
    "# Analyze network motifs\n",
    "def find_network_motifs(G):\n",
    "    \"\"\"\n",
    "    Find common 3-node motifs in directed networks\n",
    "    \"\"\"\n",
    "    motifs = {\n",
    "        'feed_forward_loops': 0,\n",
    "        'feedback_loops': 0,\n",
    "        'mutual_regulation': 0\n",
    "    }\n",
    "    \n",
    "    nodes = list(G.nodes())\n",
    "    \n",
    "    # Check all triplets of nodes\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i+1, len(nodes)):\n",
    "            for k in range(j+1, len(nodes)):\n",
    "                triplet = [nodes[i], nodes[j], nodes[k]]\n",
    "                \n",
    "                # Check for feed-forward loop: A->B, A->C, B->C\n",
    "                if (G.has_edge(triplet[0], triplet[1]) and \n",
    "                    G.has_edge(triplet[0], triplet[2]) and \n",
    "                    G.has_edge(triplet[1], triplet[2])):\n",
    "                    motifs['feed_forward_loops'] += 1\n",
    "    \n",
    "    # Check for mutual regulation (2-node motif)\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i+1, len(nodes)):\n",
    "            if G.has_edge(nodes[i], nodes[j]) and G.has_edge(nodes[j], nodes[i]):\n",
    "                motifs['mutual_regulation'] += 1\n",
    "    \n",
    "    return motifs\n",
    "\n",
    "motifs = find_network_motifs(grn)\n",
    "print(f\"\\nNetwork motifs found:\")\n",
    "for motif, count in motifs.items():\n",
    "    print(f\"{motif}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze GRN properties\n",
    "grn_metrics = calculate_network_metrics(grn.to_undirected())  # Convert to undirected for some metrics\n",
    "\n",
    "# Add directed network specific metrics\n",
    "in_degree = dict(grn.in_degree())\n",
    "out_degree = dict(grn.out_degree())\n",
    "\n",
    "grn_df = pd.DataFrame({\n",
    "    'gene': list(grn.nodes()),\n",
    "    'in_degree': [in_degree[node] for node in grn.nodes()],\n",
    "    'out_degree': [out_degree[node] for node in grn.nodes()],\n",
    "    'total_degree': [grn_metrics['degree'][node] for node in grn.nodes()],\n",
    "    'betweenness': [grn_metrics['betweenness'][node] for node in grn.nodes()]\n",
    "})\n",
    "\n",
    "# Classify genes by regulatory role\n",
    "grn_df['role'] = 'Intermediate'\n",
    "grn_df.loc[grn_df['out_degree'] >= 3, 'role'] = 'Master_Regulator'\n",
    "grn_df.loc[(grn_df['in_degree'] >= 2) & (grn_df['out_degree'] == 0), 'role'] = 'Target'\n",
    "\n",
    "print(\"Gene Regulatory Network Analysis:\")\n",
    "print(grn_df.head())\n",
    "print(f\"\\nGene roles:\")\n",
    "print(grn_df['role'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i grn_df -w 12 -h 8\n",
    "\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "\n",
    "# Gene regulatory network analysis plot\n",
    "p5 <- ggplot(grn_df, aes(x = in_degree, y = out_degree, color = role, size = betweenness)) +\n",
    "    geom_point(alpha = 0.7) +\n",
    "    scale_color_manual(values = c(\n",
    "        \"Master_Regulator\" = \"red\",\n",
    "        \"Target\" = \"blue\",\n",
    "        \"Intermediate\" = \"gray\"\n",
    "    )) +\n",
    "    scale_size_continuous(range = c(2, 6)) +\n",
    "    labs(\n",
    "        title = \"Gene Regulatory Network Analysis\",\n",
    "        subtitle = \"Classification by regulatory role\",\n",
    "        x = \"In-degree (Regulated by)\",\n",
    "        y = \"Out-degree (Regulates)\",\n",
    "        color = \"Gene Role\",\n",
    "        size = \"Betweenness\\nCentrality\"\n",
    "    ) +\n",
    "    theme_classic() +\n",
    "    theme(\n",
    "        plot.title = element_text(size = 16, hjust = 0.5),\n",
    "        plot.subtitle = element_text(size = 12, hjust = 0.5),\n",
    "        axis.title = element_text(size = 12),\n",
    "        axis.text = element_text(size = 10),\n",
    "        legend.title = element_text(size = 12),\n",
    "        legend.text = element_text(size = 10)\n",
    "    ) +\n",
    "    annotate(\"text\", x = 0.5, y = 3.5, label = \"Master\\nRegulators\", size = 3, color = \"red\") +\n",
    "    annotate(\"text\", x = 2.5, y = 0.2, label = \"Targets\", size = 3, color = \"blue\")\n",
    "\n",
    "print(p5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Interactive Problem-Solving\n",
    "\n",
    "### Problem 5.1: Metabolic Network Robustness\n",
    "\n",
    "Analyze how removing reactions affects network connectivity and flux capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_network_robustness(S, reaction_names):\n",
    "    \"\"\"\n",
    "    Analyze metabolic network robustness by removing reactions\n",
    "    \"\"\"\n",
    "    original_rank = linalg.matrix_rank(S)\n",
    "    original_null_dim = S.shape[1] - original_rank\n",
    "    \n",
    "    robustness_results = []\n",
    "    \n",
    "    for i, reaction in enumerate(reaction_names):\n",
    "        # Remove reaction i\n",
    "        S_reduced = np.delete(S, i, axis=1)\n",
    "        \n",
    "        # Calculate new properties\n",
    "        new_rank = linalg.matrix_rank(S_reduced)\n",
    "        new_null_dim = S_reduced.shape[1] - new_rank\n",
    "        \n",
    "        robustness_results.append({\n",
    "            'removed_reaction': reaction,\n",
    "            'original_null_dim': original_null_dim,\n",
    "            'new_null_dim': new_null_dim,\n",
    "            'flux_capacity_change': new_null_dim - original_null_dim,\n",
    "            'is_essential': new_null_dim < original_null_dim\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(robustness_results)\n",
    "\n",
    "# Analyze robustness of our metabolic network\n",
    "robustness_df = analyze_network_robustness(S_metabolic, reactions)\n",
    "\n",
    "print(\"Network Robustness Analysis:\")\n",
    "print(robustness_df)\n",
    "print(f\"\\nEssential reactions (reduce flux capacity):\")\n",
    "essential_reactions = robustness_df[robustness_df['is_essential']]\n",
    "print(essential_reactions[['removed_reaction', 'flux_capacity_change']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.2: Your Turn - Network Centrality Analysis\n",
    "\n",
    "**Challenge**: Compare different centrality measures and identify the most \"important\" proteins in the PPI network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function to rank proteins by different centrality measures\n",
    "def rank_proteins_by_centrality(network_df, top_n=5):\n",
    "    \"\"\"\n",
    "    Rank proteins by different centrality measures\n",
    "    \n",
    "    Parameters:\n",
    "    network_df: DataFrame with centrality measures\n",
    "    top_n: Number of top proteins to return\n",
    "    \"\"\"\n",
    "    centrality_measures = ['degree', 'betweenness', 'closeness', 'eigenvector']\n",
    "    \n",
    "    rankings = {}\n",
    "    \n",
    "    for measure in centrality_measures:\n",
    "        # TODO: Sort proteins by centrality measure and get top_n\n",
    "        top_proteins = network_df.nlargest(top_n, measure)[['protein', measure]]\n",
    "        rankings[measure] = top_proteins\n",
    "    \n",
    "    return rankings\n",
    "\n",
    "# Test your implementation\n",
    "protein_rankings = rank_proteins_by_centrality(network_df)\n",
    "\n",
    "print(\"Top 5 proteins by different centrality measures:\")\n",
    "for measure, ranking in protein_rankings.items():\n",
    "    print(f\"\\n{measure.capitalize()} centrality:\")\n",
    "    print(ranking.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **Linear Algebra Applications**: Matrix operations for biological network analysis\n",
    "2. **Flux Balance Analysis**: Optimization of metabolic networks using linear programming\n",
    "3. **Principal Component Analysis**: Dimensionality reduction for omics data\n",
    "4. **Network Theory**: Graph analysis of biological interaction networks\n",
    "5. **Network Motifs**: Common patterns in biological networks and their functions\n",
    "6. **Centrality Analysis**: Identifying important nodes in biological networks\n",
    "\n",
    "### Biological Insights\n",
    "\n",
    "- **Stoichiometric constraints** limit possible flux distributions in metabolism\n",
    "- **Hub proteins** are often essential and disease-related\n",
    "- **Network motifs** represent evolutionary-selected functional modules\n",
    "- **Principal components** reveal hidden structure in high-dimensional biological data\n",
    "- **Network robustness** determines system resilience to perturbations\n",
    "\n",
    "### Mathematical Connections\n",
    "\n",
    "- **Null space analysis** reveals steady-state solutions\n",
    "- **Eigenvalue decomposition** underlies both PCA and network centrality\n",
    "- **Linear programming** optimizes biological objective functions\n",
    "- **Graph theory** quantifies network topology and function\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore dynamic network models\n",
    "- Learn about network control theory\n",
    "- Study multi-layer biological networks\n",
    "- Apply these methods to real biological datasets\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've completed the Linear Algebra and Network Theory module of BIO559R Mathematical Foundations. 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

